{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from typing import List\n",
    "\n",
    "test_images_path = 'human_in_the_loop/train'\n",
    "output_path = 'augmented'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply mirror data augmentation on livecell_test_images/A172"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_files = natsorted(glob('human_in_the_loop/train/*.tif'))\n",
    "\n",
    "width = 256\n",
    "height = 256   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mirror_half(image: np.ndarray, half: str) -> np.ndarray:\n",
    "    if half == 'left':\n",
    "        half = image[:, :width//2]\n",
    "    elif half == 'right':\n",
    "        half = image[:, width//2:]\n",
    "    else:\n",
    "        raise ValueError('Invalid half. Choose from \"left\" or \"right\".')\n",
    "        \n",
    "    augmented_image = np.concatenate((half, cv2.flip(half, 1)), axis=1)\n",
    "\n",
    "    return augmented_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tifffile\n",
    "\n",
    "for image_file in image_files:\n",
    "    image_path = image_file\n",
    "    image = tifffile.imread(image_path)\n",
    "    \n",
    "    for half in ['left', 'right']:\n",
    "        augmented_image = mirror_half(image, half)\n",
    "        output_file_path = os.path.join(output_path, f'{half}_mirrored_{os.path.basename(image_file)}')\n",
    "        # Convert the image to BGR color space before saving\n",
    "        tifffile.imwrite(output_file_path, augmented_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from natsort import natsorted\n",
    "\n",
    "labels_list = natsorted(glob('human_in_the_loop/test/*.npy'))\n",
    "labels = []\n",
    "\n",
    "for lbl in labels_list:\n",
    "    labels.append(np.load(lbl, allow_pickle=True).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0, ...,  0,  0,  0],\n",
       "       [ 0,  1,  1, ...,  0,  0,  0],\n",
       "       [ 0,  1,  0, ...,  0,  0,  0],\n",
       "       ...,\n",
       "       [ 0,  0,  0, ...,  0,  0, 80],\n",
       "       [ 0,  0,  0, ...,  0,  0, 80],\n",
       "       [ 0,  0,  0, ..., 80, 80, 80]], dtype=uint16)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[0]['outlines']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "labell = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tifffile\n",
    "\n",
    "for i, image_file in enumerate(labels_list):\n",
    "    image_path = image_file\n",
    "    #image = tifffile.imread(image_path)\n",
    "    image = labels[i]['outlines']\n",
    "    \n",
    "    for half in ['left', 'right']:\n",
    "        augmented_image = mirror_half(image, half)\n",
    "        labell[i]['outlines'] = augmented_image\n",
    "        \n",
    "        output_file_path = os.path.join(output_path, f'{half}_mirrored_{os.path.basename(image_file)}')\n",
    "        # Convert the image to BGR color space before saving\n",
    "        np.save(output_file_path, labell[i], allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def mirror_half(label_path: str, half: str) -> np.ndarray:\n",
    "    label = np.load(label_path, allow_pickle=True)\n",
    "\n",
    "    if half == 'left':\n",
    "        half = label[:, :width//2]\n",
    "    elif half == 'right':\n",
    "        half = label[:, width//2:]\n",
    "    else:\n",
    "        raise ValueError('Invalid half. Choose from \"left\" or \"right\".')\n",
    "\n",
    "    augmented_label = np.concatenate((half, np.flip(half, 1)), axis=1)\n",
    "\n",
    "    return augmented_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 0-dimensional, but 2 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m label_path \u001b[38;5;241m=\u001b[39m label_file\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m half \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mright\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m----> 5\u001b[0m     augmented_label \u001b[38;5;241m=\u001b[39m \u001b[43mmirror_half\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhalf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     output_file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_path, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhalf\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_mirrored_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabel_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      7\u001b[0m     np\u001b[38;5;241m.\u001b[39msave(output_file_path, augmented_label)\n",
      "Cell \u001b[0;32mIn[22], line 7\u001b[0m, in \u001b[0;36mmirror_half\u001b[0;34m(label_path, half)\u001b[0m\n\u001b[1;32m      4\u001b[0m label \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(label_path, allow_pickle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m half \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m----> 7\u001b[0m     half \u001b[38;5;241m=\u001b[39m \u001b[43mlabel\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43mwidth\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m half \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mright\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m      9\u001b[0m     half \u001b[38;5;241m=\u001b[39m label[:, width\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m:]\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array: array is 0-dimensional, but 2 were indexed"
     ]
    }
   ],
   "source": [
    "for label_file in labels_list:\n",
    "    label_path = label_file\n",
    "    \n",
    "    for half in ['left', 'right']:\n",
    "        augmented_label = mirror_half(label_path, half)\n",
    "        output_file_path = os.path.join(output_path, f'{half}_mirrored_{label_file}')\n",
    "        np.save(output_file_path, augmented_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mirror_corner(image: np.ndarray, corner: str) -> np.ndarray:\n",
    "    if corner == 'upper_left':\n",
    "        selected_corner = image[:height//2, :width//2]\n",
    "    elif corner == 'upper_right':\n",
    "        selected_corner = image[:height//2, width//2:]\n",
    "    elif corner == 'lower_left':\n",
    "        selected_corner = image[height//2:, :width//2]\n",
    "    elif corner == 'lower_right':\n",
    "        selected_corner = image[height//2:, width//2:]\n",
    "    else:\n",
    "        raise ValueError('Invalid corner. Choose from \"upper_left\", \"upper_right\", \"lower_left\", \"lower_right\".')\n",
    "\n",
    "    augmented_image = np.concatenate((selected_corner, cv2.flip(selected_corner, 1)), axis=1)\n",
    "    augmented_image = np.concatenate((augmented_image, cv2.flip(augmented_image, 0)), axis=0)\n",
    "    \n",
    "    return augmented_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_file in image_files:\n",
    "    image_path = os.path.join(test_images_path, image_file)\n",
    "    image = cv2.imread(image_path)\n",
    "    \n",
    "    for corner in ['upper_left', 'upper_right', 'lower_left', 'lower_right']:\n",
    "        augmented_image = mirror_corner(image, corner)\n",
    "        output_file_path = os.path.join(output_path, f'{corner}_mirrored_{image_file}')\n",
    "        cv2.imwrite(output_file_path, augmented_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_gaussian_noise(image: np.ndarray, mean: float = 0.0, std_dev: float = 0.2) -> np.ndarray:\n",
    "    noise = np.random.normal(mean, std_dev, image.shape).astype(np.uint8)\n",
    "    noisy_image = cv2.add(image, noise)\n",
    "    return noisy_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_brightness_contrast(image: np.ndarray, brightness: int = 50, contrast: int = 50) -> np.ndarray:\n",
    "    new_image = np.zeros(image.shape, image.dtype)\n",
    "    alpha = 1.0 + contrast / 100.0\n",
    "    beta = brightness\n",
    "    new_image = cv2.convertScaleAbs(image, alpha=alpha, beta=beta)\n",
    "    return new_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_scale(image, scale_range):\n",
    "    scale = np.random.uniform(scale_range[0], scale_range[1])\n",
    "    new_size = (int(image.shape[1] * scale), int(image.shape[0] * scale))\n",
    "\n",
    "    new_size = (min(new_size[0], image.shape[1]), min(new_size[1], image.shape[0]))\n",
    "\n",
    "    x = np.random.randint(0, image.shape[1] - new_size[0] + 1)\n",
    "    y = np.random.randint(0, image.shape[0] - new_size[1] + 1)\n",
    "\n",
    "    # Crop the image to the new size and scale it back to the original size\n",
    "    cropped = image[y:y + new_size[1], x:x + new_size[0]]\n",
    "    scaled_image = cv2.resize(cropped, (image.shape[1], image.shape[0]))\n",
    "\n",
    "    return scaled_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_file in image_files:\n",
    "    image_path = os.path.join(test_images_path, image_file)\n",
    "    image = cv2.imread(image_path)\n",
    "    \n",
    "    # Add Gaussian noise\n",
    "    noisy_image = add_gaussian_noise(image)\n",
    "    output_file_path = os.path.join(output_path, f'noisy_{image_file}')\n",
    "    cv2.imwrite(output_file_path, noisy_image)\n",
    "    \n",
    "    # Change brightness and contrast\n",
    "    adjusted_image = change_brightness_contrast(image)\n",
    "    output_file_path = os.path.join(output_path, f'adjusted_{image_file}')\n",
    "    cv2.imwrite(output_file_path, adjusted_image)\n",
    "    \n",
    "    # Randomly scale the image\n",
    "    scaled_image = random_scale(image, scale_range=(0.5, 1.5))\n",
    "    output_file_path = os.path.join(output_path, f'scaled_{image_file}')\n",
    "    cv2.imwrite(output_file_path, scaled_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vTerra",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
